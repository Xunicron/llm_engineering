{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 74701a8c35f6: 100% ▕██████████████████▏ 1.3 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 4f659a1e86d7: 100% ▕██████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 74701a8c35f6: 100% ▕██████████████████▏ 1.3 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 4f659a1e86d7: 100% ▕██████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality, engaging content such as articles, videos, and social media posts without the need for human writers or producers. This can be particularly useful in industries like finance, healthcare, and technology where content is a key aspect of their offerings.\n",
      "2. **Marketing Automation**: Generative AI can help automate repetitive marketing tasks such as email campaigns, lead generation, and personalization. By analyzing customer data and preferences, generative AI can create targeted and personalized messages that drive conversions.\n",
      "3. **Customer Service**: Generative AI-powered chatbots can be used to provide 24/7 customer support, answering common questions and routing complex issues to human representatives. This can improve customer satisfaction, reduce support costs, and enhance overall customer experience.\n",
      "4. **Supply Chain Optimization**: Generative AI can help optimize supply chain operations by predicting demand, identifying potential bottlenecks, and suggesting alternative logistics routes. This can lead to improved efficiency, reduced waste, and increased competitiveness.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from equipment and predict when maintenance is required, reducing downtime and increasing overall operational efficiency.\n",
      "6. **Design and Product Development**: Generative AI can be used to generate new designs, product prototypes, and even entire products based on customer feedback, market trends, and design principles.\n",
      "7. **Healthcare**: Generative AI can help analyze medical images, identify patterns in patient data, and create personalized treatment plans. It can also assist in predicting disease outcomes and optimizing treatment strategies.\n",
      "8. **Financial Analysis**: Generative AI can help analyze large datasets to identify trends, predict market fluctuations, and optimize investment portfolios.\n",
      "9. **Quality Control**: Generative AI can be used to monitor and improve the quality of products by analyzing sensor data from manufacturing processes and identifying potential issues before they become major problems.\n",
      "10. **Research and Development**: Generative AI can help scientists and researchers explore new ideas, simulate experiments, and analyze complex data sets.\n",
      "\n",
      "Some specific companies that are already applying generative AI in various business applications include:\n",
      "\n",
      "* Google's AI team is using generative AI to create personalized products and services for users.\n",
      "* Amazon is using generative AI to optimize its supply chain operations and reduce waste.\n",
      "* Microsoft is developing a range of generative AI-powered tools for businesses, including a chatbot that can answer customer queries and suggest solutions.\n",
      "* IBM is using generative AI to improve healthcare outcomes by analyzing patient data and identifying patterns in medical research.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Product Design and Development**: Generative AI can be used to create innovative products, such as furniture, clothing, and home decor, that are tailored to specific customer needs and preferences. Companies like IKEA and Nike have already started using generative AI in their product design processes.\n",
      "2. **Content Generation**: Generative AI can generate high-quality content, such as articles, social media posts, and even entire books, saving time and resources for businesses looking to produce more content quickly.\n",
      "3. **Customer Service Chatbots**: Generative AI-powered chatbots can analyze customer queries, provide personalized responses, and route complex issues to human customer support agents, improving the overall customer experience.\n",
      "4. **Marketing Automation**: Generative AI can help automate marketing tasks such as email campaigns, social media advertising, and lead generation, allowing businesses to focus on more strategic activities.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and increasing overall efficiency.\n",
      "6. **Supply Chain Optimization**: Generative AI can analyze historical data and predict demand patterns, allowing businesses to optimize their supply chain and reduce inventory levels.\n",
      "7. **Customer Profiling and Segmentation**: Generative AI can create detailed customer profiles based on behavior, preferences, and demographics, enabling targeted marketing campaigns and improved customer service.\n",
      "8. **Virtual Assistants**: Generative AI-powered virtual assistants, such as Amazon Alexa and Google Assistant, can perform tasks such as scheduling appointments, sending reminders, and making reservations, freeing up human staff to focus on more complex tasks.\n",
      "9. **Automated Quality Control**: Generative AI can analyze images and videos to detect defects, anomalies, and quality issues, allowing businesses to streamline their quality control processes and reduce production costs.\n",
      "10. **Research and Development**: Generative AI can assist in the discovery of new materials, designs, and applications by analyzing large datasets and identifying patterns and correlations.\n",
      "\n",
      "These business applications of generative AI have the potential to transform various industries, from healthcare and finance to manufacturing and logistics, by increasing efficiency, reducing costs, and improving customer experiences.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications, offering potential solutions for various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality, engaging content such as articles, social media posts, and videos. Companies can leverage this technology to streamline their content creation efforts, reduce costs, and increase efficiency.\n",
      "2. **Design Automation**: Generative AI can automate the design process for products, from initial concept to final production-ready designs. This helps manufacturers save time, reduce errors, and improve product accuracy.\n",
      "3. **Product Optimization**: By generating data-driven insights on customer behavior, preferences, and needs, generative AI can help businesses optimize their products and services. For instance, companies can use this data to identify areas for improvement and create targeted marketing campaigns.\n",
      "4. **Research and Development**: Generative AI can aid in the design of new products, processes, and materials by generating vast amounts of data. This can accelerate R&D efforts, reduce the time-to-market, and help companies innovate faster.\n",
      "5. **Digital Twinning**: Generative AI enables the creation of digital twins, which are virtual replicas of physical systems, processes, or products. Digital twinning helps optimize system performance, predict maintenance needs, and improve supply chain efficiency.\n",
      "6. **Predictive Maintenance**: By analyzing vast amounts of sensor data, generative AI can identify potential issues before they occur, reducing downtime and improving overall equipment effectiveness (OEE).\n",
      "7. **Personalized Marketing**: Generative AI can generate personalized content, such as recommendatory items or ads tailored to individual customer preferences. This enables businesses to enhance the user experience and increase customer engagement.\n",
      "8. **Supply Chain Optimization**: Generative AI can help optimize supply chains by analyzing data on inventory levels, transportation routes, and production schedules. This leads to reduced logistics costs, increased efficiency, and improved product availability.\n",
      "9. **Image and Video Editing**: Generative AI can automate image and video editing tasks, such as object detection, color correction, and scene composition. This enhances content creation for various applications, including social media, advertising, and streaming platforms.\n",
      "10. **Robotics Automation**: Generative AI can assist in the design of robots, which can perform a wide range of tasks autonomously or with human intervention. By generating data-driven solutions, businesses can reduce development time, decrease costs, and enhance productivity.\n",
      "11. **Natural Language Processing (NLP)**: Generative AI enhances NLP by enabling the creation of conversational interfaces for various applications, such as customer service chatbots, language translation systems, and text summarization tools.\n",
      "12. **Machine Learning Model Deployment**: Generative AI can accelerate machine learning model deployment by generating hyperparameters, optimizing algorithms, and refining model performance. This helps companies save time, reduce costs, and improve data-driven decision-making.\n",
      "\n",
      "These business applications of generative AI are constantly evolving, and new use cases continue to emerge as the technology advances and becomes more sophisticated.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the basic concepts undercores of language models (LLMs), specifically explaining what neural networks are, how attention works in them, and what a transformer is. Hmm, I've heard these terms before, but I'm not entirely sure about all the details. Let me try to break this down step by step.\n",
      "\n",
      "Starting with neural networks. From what I remember, they're a type of machine learning model that tries to simulate the way the human brain processes information. They have layers of perceptrons or nodes, connected in a way that resembles biological neural nets. Each node can process incoming data and pass an activation forward. Then these are used for predictions or classifications.\n",
      "\n",
      "Wait, but how do they work? I think each layer in a neural network has specific functions. Like, the input layer receives the data, followed by one or more hidden layers processing it, and then an output layer that makes the prediction. But why multiple layers together? Oh, because each layer can extract different features from the data, combined to give a better overall understanding.\n",
      "\n",
      "Now, attention in LLMs. I've heard this term thrown around a lot. It probably has something to do with how models focus on certain parts of their input or output when making decisions. Maybe it's about paying more attention to specific words or words that are really important. So like, if the model is translating, it might focus more on pronouns and avoid those words so as not to make the translation lose meaning.\n",
      "\n",
      "What does a transformer exactly do? I think I've come across the term before. It mentions something called 'attention in deep learning.' Maybe I should compare it to how transformers are used in NLP tasks. So, a transformer is like a sequence of layers that both process and attend to different parts of the input sequence.\n",
      "\n",
      "Hmm, attention mechanisms allow the model to pay attention not just to all the past tokens in the sentence but also look back further. Wait, does that mean they can focus on different contexts in the input? For example, if you're translating a sentence, the model might be better at focusing on certain pronouns or clauses because those are more informative.\n",
      "\n",
      "But how exactly do attention work within the transformer architecture? Are these attention mechanisms applied across multiple dimensions of the data? Maybe each token in the sequence is connected to all other tokens to compute their embeddings and then determine which ones are relevant. This could help in learning multi-level interactions between different parts of the input, improving understanding and generating more nuanced outputs.\n",
      "\n",
      "Putting it all together, a neural network processes information through layers that transform input into output, with activation functions playing a role during this flow. Attention allows the model to focus on specific or non-local parts of its input by using attention mechanisms in each component's processing. The transformer's architecture likely uses these multi-dimensional attention mechanisms within its layers to better understand and generate sequences, especially those presented as text.\n",
      "\n",
      "Wait, do I have all the details right? Maybe there are terms like embeddings that come into play before the attention can occur effectively. And while not all LLMs use transformers, many do, especially large ones with their hidden layers. Also, techniques like positional encodings might be part of the model preprocessing steps to handle variable-length inputs effectively.\n",
      "\n",
      "I should make sure definitions are accurate. For neural networks, they're composed of layers like input, hidden, and output, each transforming data through activation functions. Attention in LLMs refers to modeling how models efficiently focus on specific parts using a mechanism that weights connections during the forward pass, which helps in improving context understanding by capturing interaction between distant tokens.\n",
      "\n",
      "And the transformer itself is a sequence of self-attention layers, where each layer applies attention over its input sequence while also processing it and merging the output into the next encoder or decoder layers. This effectively allows the model to capture long-range dependencies and understand various sequences appropriately.\n",
      "\n",
      "So summarizing my thoughts: Neural networks handle data through multiple layers with activation functions. Attention in LLMs allows focusing on specific parts, improving understanding based on interactions between distant elements. Transformers are neural networks that process each token sequence while attending to its own context, effectively capturing multi-level interactions for better outputs.\n",
      "</think>\n",
      "\n",
      "**Neural Networks in Language Models: A Deep Dive**\n",
      "\n",
      "Neural networks (NNs) constitute the foundational components of language models, offering a structured approach to processing and understanding information through layers of interconnected nodes. These layers simulate the biological neural net functions, facilitating data transformation and activation flow. The network's input passes through hidden layers, each progressively refining features until an output layer makes its prediction.\n",
      "\n",
      "**Attention in LLMs: Focusing on Specific Concepts**\n",
      "\n",
      "Attention mechanisms, critical in LLMs, enable models to focus on specific or non-local parts of their input by weighting connections during processing. This mechanism allows the model to prioritize certain words or clauses, such as pronouns, enhancing translation accuracy without losing meaning. The interaction between distant tokens captures nuanced understanding, crucial for effective context extraction.\n",
      "\n",
      "**The Transformer: Its Structure and Functionality**\n",
      "\n",
      "Transformers are a class of deep learning models characterized by their ability to handle sequential data effectively. They process each token's sequence through layers that both encode the token information and attend to its context. This bidirectional flow enables models to capture long-range dependencies, exemplifying their effectiveness in various NLP tasks like text translation and summarization.\n",
      "\n",
      "In essence, a neural network transforms input data through multiple layers with activation functions, attention mechanisms enhance focus on specific concepts, and transformers employ multi-dimensional attention within each layer to build intricate representations from sequential inputs.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6b66d-efd9-4803-9a22-ea23eb05213c",
   "metadata": {},
   "source": [
    "## Website Summarizer using Llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bafc3a0-f04c-4757-a900-33dc7b077370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\"\n",
    "\n",
    "# Website class\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "# get site address\n",
    "def site_address():\n",
    "    url = input('Input the web site to summarize')\n",
    "    return url\n",
    "\n",
    "# # Define our system prompt\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "# and provides a short summary, ignoring text that might be navigation related. \\\n",
    "# Respond in markdown.\"\n",
    "\n",
    "# Define user prompt\n",
    "user_prompt = \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "\n",
    "\n",
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "def display_summary():\n",
    "    summary = ollama.chat(model=MODEL, messages=messages)\n",
    "    print(summary['message']['content'])\n",
    "    # display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e042b367-0b4d-4ad8-9250-9b3aa6ea86da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input the web site to summarize https://www.bbc.co.uk/news/articles/clynre7leyjo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff Bezos-backed $88m methane satellite missing in space - BBC News\n",
      "Here's a summary of the website in markdown:\n",
      "\n",
      "**BBC Website Summary**\n",
      "\n",
      "This website provides news, updates, and resources from the BBC on various topics such as climate change, sports, entertainment, politics, and more.\n",
      "\n",
      "**News and Announcements**\n",
      "\n",
      "* The £65m satellite designed to detect methane releases from oil and gas production has lost communication with Earth due to a power issue.\n",
      "* Google has stated that the satellite is likely not recoverable, but some of its software may still be usable.\n",
      "* A $88m pollution-tracking satellite called MethaneSat was launched last year aboard an Elon Musk SpaceX rocket but has now gone missing in space.\n",
      "\n",
      "**Environmental and Science News**\n",
      "\n",
      "* The loss of MethaneSat highlights the need for more transparency on methane emissions from various sources, such as oil and gas production, agriculture, and food waste.\n",
      "* A recent study by CarbonMapper found that methane is responsible for nearly a third of human-induced warming, but its levels continue to rise despite international commitments.\n",
      "\n",
      "**Features**\n",
      "\n",
      "* BBC News\n",
      "* InDepth: Israel-Gaza war, War in Ukraine, Climate change, UK politics, and more\n",
      "* iPlayer: Watch BBC content on-demand\n",
      "* Sounds: Listen to BBC audio content online\n",
      "\n",
      "**Resources**\n",
      "\n",
      "* Bitesize: Learn about climate change, science, and more with BBC educational resources.\n",
      "* CBBC: Watch children's shows and programs from the BBC.\n",
      "* CBeebies: Watch nursery rhyme videos and stories.\n",
      "\n",
      "Please note that this summary is based on the text provided and may not reflect any updates or changes made to the website since then.\n"
     ]
    }
   ],
   "source": [
    "## Summarize site\n",
    "\n",
    "# prompt for site\n",
    "url = site_address()\n",
    "\n",
    "# Get page text\n",
    "page_text = Website(url)\n",
    "print(page_text.title)\n",
    "\n",
    "# Create user prompt and message content\n",
    "user_prompt += page_text.text\n",
    "# print(user_prompt)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# Summarize page text\n",
    "display_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86def4-0d02-4f74-a45a-ab975478bf06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
